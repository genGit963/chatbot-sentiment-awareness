# FastAPI: The web framework to create the API that will handle HTTP requests and serve the chatbot's functionality.
fastapi==0.100.0

# Uvicorn: The ASGI server for serving the FastAPI application. Itâ€™s needed to run the FastAPI app in development and production.
uvicorn==0.23.0

# torch: PyTorch is the deep learning framework used by the Hugging Face transformers library. This will be needed to run sentiment analysis models.
torch==2.1.0

# transformers: Hugging Face's library for using pre-trained models for NLP tasks. We'll use this to load the sentiment analysis model (e.g., DistilBERT).
transformers==4.33.0

# scikit-learn: A machine learning library that provides various tools for data analysis, including classification, regression, clustering, and more.
# This might be useful for additional model tuning or pre-processing in the future.
scikit-learn==1.3.1

# pydantic: A data validation and parsing library used by FastAPI for request and response models. It ensures the input data conforms to the specified format.
# pydantic==2.7.1
pydantic==1.10.7

# numpy: A library for numerical operations. It's essential for handling array-like data, used heavily in machine learning and model inference.
numpy==1.25.0

# spacy: A powerful NLP library. This is optional but can be used for text preprocessing (e.g., tokenization, lemmatization) if needed.
spacy==3.6.0

# requests: A simple HTTP library for making API requests. This can be useful for integrating external APIs or for testing purposes.
requests==2.31.0

# Gunicorn: Web server for serving FastAPI applications in production.
# Use the latest compatible version for your system.
gunicorn==23.0.0

# aiohttp: An asynchronous HTTP client/server library for Python. It may be useful if you're building any asynchronous communication with the frontend or external services.
aiohttp==3.8.5


